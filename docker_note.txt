inception
-----------------------------------------------------------------------------------------------------------

OS = Linux kernel + user mode

User mode: This is everything you use on the computer that is not the kernel — like the programs, apps, and tools you open. These run “on top” of the kernel and ask it to do things for them.

Linux kernel:	Think of it as the brain of the computer. It talks directly to the hardware (like the CPU, memory, and hard drive) and controls how everything works inside the computer. It makes sure programs get the resources they need.
				is the core system managing all hardware and system resources.

Namespaces: are a feature inside the kernel that isolate system resources for processes. They make processes see their own “private” view of things like network interfaces, process IDs, mount points, and more. This isolation is what allows containers to have separate environments.

cgroups: (control groups) are another kernel feature that limits and monitors how much CPU, memory, disk I/O, or network bandwidth groups of processes can use. It helps manage resource allocation and prevents any process group from hogging the system.

So, both namespaces and cgroups are implemented by the Linux kernel to enable containerization — namespaces provide isolation, and cgroups provide resource control.
-----------------------------------------------------------------------------------------------------------

image -> container = pull + create
container -> image = build
running VM -> VM template = export
VM template -> running VM = import
-----------------------------------------------------------------------------------------------------------

docker pull: docker pull fedora -> telling Docker to download the Fedora image from Docker Hub (or another registry) to your local machine. This makes the image available so you can use it to create or run containers.
docker image group and docker container goup is part of docker CLI (commandline interface)
docker CLI is part of docker client
docker client is the software to inetract with the docker daemon
-----------------------------------------------------------------------------------------------------------
Docker: helps you in deploying your applications more efficiently in a sandbox (called containers) to run on the host operating system i.e. Mac. The main advantage of docker is that it allows you to package software with all of its dependencies into a single standardized unit.

When you install Docker, you get two major components:
The Docker client
The Docker engine 

						_____ docker engine _____
						|						|
docker client	<-------|---> docker daemon		|
						|		  |	 |			|
						|	   container d		|--plug-ins
						|		  |	 |			|
						|		  runc			|
						|_______________________|


docker client: Ex. docker command(CLI).
				CLI or API interface used to send commands.
				docker CLI is part of docker client.
				docker client is the software to inetract with the docker daemon.

When you type commands like this into the Docker CLI, the Docker client converts them into the appropriate API payload and POSTs them to the API endpoint exposed by the Docker daemon.

docker engine:	is the core software that runs and manages containers.
				is made from many specialized tools that work together to create and run containers — The API, image builder, high-level runtime, low-level runtime, shims etc.
				At the time of writing, the major components that make up the Docker engine are the Docker daemon, the build system, containerd, runc, and various plugins such as networking and volumes. Together, these create and run containers.
				is software that makes it easy to build, ship, and run containers.

The plug-ins: in the Docker Engine context refer to optional components that extend Docker’s capabilities beyond the core runtime.

docker daemon:	(dockerd) sits above containerd and performs higher-level tasks such as exposing the Docker API, managing images, managing volumes, managing networks, and more...
				A major job of the Docker daemon is to provide an easy-to-use standard interface that abstracts the lower levels.
				The Docker daemon component implements the Docker API and can do things such as image management, networks, and volumes. However, image management is currently being removed from the daemon and implemented in containerd.

containerd:	The higher-level runtime is called containerd. This manages the entire container lifecycle including pulling images and managing runc instances.
			the containerd component of the Docker Engine makes sure Docker images are presented to runc as valid OCI bundles.
			Its sole purpose in life is to manage container lifecycle operations such as start | stop | pause | rm....
			over time it has branched out and taken on more functionality. Things like image pulls, volumes and networks.
			containerd cannot actually create containers. It uses runc to do that. It converts the required Docker image into an OCI bundle and tells runc to use this to create a new container.

runc:	The low-level runtime is called runc and is the reference implementation of Open Containers Initiative (OCI) runtime-spec. Its job is to interface with the underlying OS and start and stop containers. Every container on a Docker node was created and started by an instance of runc.
		runc is never a long-running process and exits as soon as a container is started.
		runc interfaces with the OS kernel to pull together all of the constructs necessary to create a container (namespaces, cgroups etc.). The container process is started as a child-process of runc, and as soon as it starts, runc will exit.
		containerd uses runc to create new containers. In fact, it forks a new instance of runc for every container it creates. However, once each container is created, the runc process exits. This means we can run hundreds of containers without having to run hundreds of runc instances.

shim:	The shim is integral to the implementation of daemonless containers — what we just mentioned about decoupling running containers from the daemon for things like daemon upgrades.
		Once a container’s parent runc process exits, the associated containerd-shim process becomes the container’s parent. Some of the responsibilities the shim performs as a container’s parent include:
		Keeping any STDIN and STDOUT streams open so that when the daemon is restarted, the container doesn’t terminate due to pipes being closed etc.
		Reports the container’s exit status back to the daemon.

-----------------------------------------------------------------------------------------------------------

image name = repo + tag

Docker image: are like virtual machine templates and are used to start containers. Under the hood, they are made up of one or more read-only layers, that when stacked together, make up the overall image. Docker takes care of stacking these layers and representing them as a single unified object.
Note: Docker Images are immutable means Docker images can’t ever change. Once you’ve made one, you can delete it, but you can’t modify it.
The Docker image contains all the files you packaged, which become the container’s filesystem - and it also contains a lot of metadata about the image itself. That includes a brief history of how the image was built. You can use that to see each layer of the image, and the command that built the layer.
Images - The blueprints of our application which form the basis of containers.
Base images are images that have no parent image, usually images with an OS like ubuntu, busybox or debian.
Child images are images that build on base images and add additional functionality.

container image:	A container image is read-only package that contains everything you need to run an application. It includes application code, application dependencies, a minimal set of OS constructs, and metadata. A single image can be used to start one or more containers.

Dockerfile: is a text document that contains all the commands you could call on the command line to make an image.
-----------------------------------------------------------------------------------------------------------

layer
build time
build time commands
run time
run time commands
registry
repo
tags
manifest liste
manifest
-----------------------------------------------------------------------------------------------------------

container:	is a solution for how to get the software to run without any problems when moved from one computing environment to another. This could be from a staging environment into production or maybe from a laptop to a different laptop with another operating system.
			Containers provide a logical packaging mechanism in which your applications can be abstracted from the environment in which they run. The major difference is that every container does not require its full-fledged OS. All containers on a single host sharing a single OS. This helps in frees up huge amounts of system resources such as CPU, RAM.
			Containers - Created from Docker images and run the actual application.

PID1
virtual machine
hypervisor
web template
base disks
base image
port
docker API
-----------------------------------------------------------------------------------------------------------

endpoint: virtual network interfaces responsible for making sandboxes connect to networks.
network: software implementation of an switch. (virtual switch)
libnetwork: implements the control plane and management plane functions and drivers implement the data plane.
linux drivers: 
	- bridge driver (single host)
	- MACVLAN driver (existing VLANs, single host)
	- overlay driver (multi-host)
windows drivers: nat. overlay. transport and l2bridge
CNM
host
bridge
none
-----------------------------------------------------------------------------------------------------------

Your Mac (macOS)
     │
     └──> Docker Desktop
              │
              └──> Small Linux VM (inside)
                        │
                        └──> Your Linux containers
-----------------------------------------------------------------------------------------------------------
docker-compose: is a tool for defining and running multi-container Docker applications. It allows you to define a multi-container application in a single file, then spin up the application with a single command. It is used to manage the entire lifecycle of your application, including building images, starting containers, and managing networks.
docker-compose.yml:	is the Docker Compose file that describes how Docker should deploy the app.
The standard file that Docker looks for when you run up. We define all services in an abstract way here, such that other files will complete the service definitions depending on use case.
